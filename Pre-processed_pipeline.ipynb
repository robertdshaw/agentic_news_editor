{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic AI News Editor: Comprehensive EDA Pipeline\n",
    "# -----------------------------------------------\n",
    "# This pipeline combines analysis of the Microsoft MIND dataset to prepare data\n",
    "# for an agentic AI system that selects, ranks, and rewrites news headlines\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "import json\n",
    "from textstat import flesch_reading_ease\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "\n",
    "# Create output directory for results\n",
    "output_dir = 'agentic_news_editor'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    os.makedirs(f'{output_dir}/plots')\n",
    "    os.makedirs(f'{output_dir}/processed_data')\n",
    "\n",
    "print(\"# Agentic AI News Editor - EDA Pipeline\")\n",
    "print(\"Starting EDA pipeline... Time:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ===============================================================\n",
    "# PART 1: DATA LOADING AND INITIAL EXPLORATION\n",
    "# ===============================================================\n",
    "print(\"\\n## PART 1: Data Loading and Initial Exploration\")\n",
    "\n",
    "# Load news data\n",
    "news_cols = [\"newsID\", \"category\", \"subcategory\", \"title\", \"abstract\", \"url\", \"title_entities\", \"abstract_entities\"]\n",
    "print(\"Loading news data...\")\n",
    "news_df = pd.read_csv(\"train_data/news.tsv\", sep=\"\\t\", header=None, names=news_cols)\n",
    "print(f\"News data loaded: {news_df.shape[0]} rows, {news_df.shape[1]} columns\")\n",
    "\n",
    "# Loading behaviors data\n",
    "print(\"Loading behaviors data...\")\n",
    "behaviors_cols = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "behaviors_df = pd.read_csv(\"train_data/behaviors.tsv\", sep=\"\\t\", header=None, names=behaviors_cols)\n",
    "print(f\"Behaviors data loaded: {behaviors_df.shape[0]} rows, {behaviors_df.shape[1]} columns\")\n",
    "\n",
    "# Store news_ids for reference\n",
    "news_ids = set(news_df[\"newsID\"])\n",
    "\n",
    "# Sample display of news data\n",
    "print(\"\\nSample news data:\")\n",
    "print(news_df.head(3))\n",
    "\n",
    "# Sample display of behaviors data\n",
    "print(\"\\nSample behaviors data:\")\n",
    "print(behaviors_df.head(3))\n",
    "\n",
    "# ===============================================================\n",
    "# PART 5: PREPARE DATA FOR THE AGENTIC NEWS EDITOR\n",
    "# ===============================================================\n",
    "print(\"\\n## PART 5: Data Preparation for Agentic News Editor\")\n",
    "\n",
    "# 1. Clean and process news data\n",
    "print(\"Preparing news data...\")\n",
    "news_df_cleaned = news_df.copy()\n",
    "\n",
    "# Filter out articles with very short titles or abstracts\n",
    "news_df_cleaned = news_df_cleaned[news_df_cleaned['title_length'] >= 10]\n",
    "news_df_cleaned = news_df_cleaned[news_df_cleaned['abstract_length'] >= 20]\n",
    "\n",
    "# Add reading ease score if not already added\n",
    "if 'title_reading_ease' not in news_df_cleaned.columns:\n",
    "    news_df_cleaned = calculate_reading_scores(news_df_cleaned)\n",
    "\n",
    "# 2. Prepare behavior data\n",
    "print(\"Preparing behavior data...\")\n",
    "\n",
    "# Add CTR data to news articles\n",
    "article_ctr_data = impressions_df.groupby('news_id').agg({\n",
    "    'clicked': ['sum', 'count']\n",
    "})\n",
    "article_ctr_data.columns = ['total_clicks', 'total_impressions']\n",
    "article_ctr_data['ctr'] = article_ctr_data['total_clicks'] / article_ctr_data['total_impressions']\n",
    "\n",
    "# Merge CTR data with news data\n",
    "news_with_engagement = news_df_cleaned.merge(\n",
    "    article_ctr_data.reset_index(),\n",
    "    left_on='newsID',\n",
    "    right_on='news_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing engagement data with zeros\n",
    "engagement_columns = ['total_clicks', 'total_impressions', 'ctr']\n",
    "news_with_engagement[engagement_columns] = news_with_engagement[engagement_columns].fillna(0)\n",
    "\n",
    "# 3. Create dataset for title rewriting task\n",
    "print(\"Creating dataset for headline rewriting task...\")\n",
    "\n",
    "# Filter to articles with sufficient impressions for reliable CTR data\n",
    "rewriting_candidates = news_with_engagement[news_with_engagement['total_impressions'] >= 5].copy()\n",
    "\n",
    "# Group titles by reading ease score to identify good and bad examples\n",
    "rewriting_candidates['reading_ease_bin'] = pd.qcut(\n",
    "    rewriting_candidates['title_reading_ease'], \n",
    "    q=5, \n",
    "    labels=['Very Hard', 'Hard', 'Medium', 'Easy', 'Very Easy']\n",
    ")\n",
    "\n",
    "# Create a dataset to show examples from different readability levels\n",
    "rewriting_examples = {}\n",
    "for readability_level in rewriting_candidates['reading_ease_bin'].unique():\n",
    "    group_df = rewriting_candidates[rewriting_candidates['reading_ease_bin'] == readability_level]\n",
    "    \n",
    "    # Get high and low CTR examples from this readability group\n",
    "    high_ctr = group_df.nlargest(5, 'ctr')\n",
    "    low_ctr = group_df.nsmallest(5, 'ctr')\n",
    "    \n",
    "    rewriting_examples[readability_level] = {\n",
    "        'high_ctr': high_ctr[['newsID', 'title', 'category', 'ctr', 'title_reading_ease']].to_dict('records'),\n",
    "        'low_ctr': low_ctr[['newsID', 'title', 'category', 'ctr', 'title_reading_ease']].to_dict('records')\n",
    "    }\n",
    "\n",
    "# 4. Save processed data for the news editor system\n",
    "print(\"Saving processed data...\")\n",
    "\n",
    "# Save the cleaned news data with engagement metrics\n",
    "news_with_engagement.to_csv(f'{output_dir}/processed_data/news_with_engagement.csv', index=False)\n",
    "\n",
    "# Save headline rewriting examples dataset\n",
    "with open(f'{output_dir}/processed_data/headline_rewriting_examples.json', 'w') as f:\n",
    "    json.dump(rewriting_examples, f, indent=2)\n",
    "\n",
    "# Save category and subcategory distributions for editorial diversity goals\n",
    "category_distribution = news_df['category'].value_counts().to_dict()\n",
    "with open(f'{output_dir}/processed_data/category_distribution.json', 'w') as f:\n",
    "    json.dump(category_distribution, f, indent=2)\n",
    "\n",
    "# Create an editorial guideline summary based on the analysis\n",
    "category_ctr_summary = category_ctr.reset_index().to_dict('records')\n",
    "headline_insights = {\n",
    "    'reading_ease_correlation': correlations['ctr']['title_reading_ease'],\n",
    "    'headline_patterns': {\n",
    "        'high_engagement': high_ctr_patterns,\n",
    "        'low_engagement': low_ctr_patterns\n",
    "    }\n",
    "}\n",
    "\n",
    "editorial_guidelines = {\n",
    "    'category_performance': category_ctr_summary,\n",
    "    'headline_insights': headline_insights,\n",
    "    'overall_ctr_benchmark': clicks/total\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/processed_data/editorial_guidelines.json', 'w') as f:\n",
    "    json.dump(editorial_guidelines, f, indent=2)\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"EDA Pipeline completed! Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Processed data saved to '{output_dir}/processed_data/'\")\n",
    "print(f\"Visualizations saved to '{output_dir}/plots/'\")\n",
    "print(f\"Ready for Agentic AI News Editor development!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c4081e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

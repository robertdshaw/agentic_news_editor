{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96395ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load behaviors data\n",
    "behaviors_cols = [\"impression_id\", \"user_id\", \"time\", \"history\", \"impressions\"]\n",
    "behaviors_df = pd.read_csv(\"train_data/behaviors.tsv\", sep=\"\\t\", header=None, names=behaviors_cols)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_impressions = behaviors_df.duplicated(subset=[\"impression_id\"]).sum()\n",
    "print(f\"Duplicate impression IDs: {duplicate_impressions}\")\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing values in behaviors data:\")\n",
    "print(behaviors_df.isnull().sum())\n",
    "\n",
    "# Parse impressions into expanded format\n",
    "print(\"\\nParsing impression logs...\")\n",
    "impressions_expanded = []\n",
    "for _, row in behaviors_df.iterrows():\n",
    "    impression_items = row['impressions'].split()\n",
    "    for item in impression_items:\n",
    "        parts = item.split('-')\n",
    "        if len(parts) == 2:\n",
    "            news_id, click = parts\n",
    "            impressions_expanded.append({\n",
    "                'impression_id': row['impression_id'],\n",
    "                'user_id': row['user_id'],\n",
    "                'news_id': news_id,\n",
    "                'clicked': int(click)\n",
    "            })\n",
    "\n",
    "impressions_df = pd.DataFrame(impressions_expanded)\n",
    "print(f\"Expanded to {len(impressions_df)} impression records\")\n",
    "\n",
    "# Check for invalid news IDs (not in news_df)\n",
    "news_ids = set(news_df[\"newsID\"])\n",
    "invalid_news_ids = impressions_df[~impressions_df[\"news_id\"].isin(news_ids)]\n",
    "print(f\"Impression records with invalid news IDs: {len(invalid_news_ids)}\")\n",
    "\n",
    "# Check click distribution\n",
    "clicks = impressions_df[\"clicked\"].sum()\n",
    "total = len(impressions_df)\n",
    "print(f\"\\nOverall CTR: {clicks/total:.4f} ({clicks} clicks out of {total} impressions)\")\n",
    "\n",
    "# Check for articles with too few impressions (unreliable CTR)\n",
    "article_impressions = impressions_df.groupby(\"news_id\").size()\n",
    "low_impression_articles = (article_impressions < 5).sum()\n",
    "print(f\"Articles with fewer than 5 impressions: {low_impression_articles}\")\n",
    "\n",
    "# Check for extreme CTRs (potential data issues)\n",
    "article_ctrs = impressions_df.groupby(\"news_id\")[\"clicked\"].mean()\n",
    "suspicious_ctrs = ((article_ctrs == 0) | (article_ctrs > 0.7)).sum()\n",
    "print(f\"Articles with suspicious CTRs (0 or >70%): {suspicious_ctrs}\")\n",
    "\n",
    "# Potential adjustments based on exploration:\n",
    "# 1. Filter out articles with too few impressions (e.g., < 10)\n",
    "# 2. Investigate articles with extreme CTRs\n",
    "# 3. Set minimum threshold for impression count when calculating CTR"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

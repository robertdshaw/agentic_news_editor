{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232b06d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rshaw\\Desktop\\EC Utbildning - Data Science\\Thesis\\Agentic_AI_News_Editor project\\agentic_ai_editor_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded DistilBERT model successfully\n",
      "Model test passed. Output shape: torch.Size([1, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load models\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    bert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    bert_model = bert_model.to(device)\n",
    "    print(\"Loaded DistilBERT model successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load DistilBERT model: {e}\")\n",
    "    \n",
    "test_input = tokenizer(\"Test headline\", return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    output = bert_model(**test_input)\n",
    "print(\"Model test passed. Output shape:\", output.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef81ec7f",
   "metadata": {},
   "source": [
    "## Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846fee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to call load_training_data()\n",
      "Loaded 95492 headlines with CTR data\n",
      "\n",
      "Data preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsID</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "      <th>title_length</th>\n",
       "      <th>abstract_length</th>\n",
       "      <th>title_reading_ease</th>\n",
       "      <th>news_id</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>total_impressions</th>\n",
       "      <th>ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>77.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>news</td>\n",
       "      <td>newsscienceandtechnology</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPads</td>\n",
       "      <td>Apple's new iPad releases bring big deals on l...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AABmf2I.html</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>6.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N23144</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>29</td>\n",
       "      <td>116</td>\n",
       "      <td>90.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N93187</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "      <td>63</td>\n",
       "      <td>196</td>\n",
       "      <td>101.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N75236</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "      <td>59</td>\n",
       "      <td>99</td>\n",
       "      <td>82.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   newsID   category               subcategory  \\\n",
       "0  N88753  lifestyle           lifestyleroyals   \n",
       "1  N45436       news  newsscienceandtechnology   \n",
       "2  N23144     health                weightloss   \n",
       "3  N93187       news                 newsworld   \n",
       "4  N75236     health                    voices   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1    Walmart Slashes Prices on Last-Generation iPads   \n",
       "2                      50 Worst Habits For Belly Fat   \n",
       "3  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "4  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  Apple's new iPad releases bring big deals on l...   \n",
       "2  These seemingly harmless habits are holding yo...   \n",
       "3  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "4  I felt like I was a fraud, and being an NBA wi...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
       "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "3  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "4  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                   abstract_entities  title_length  \\\n",
       "0                                                 []            70   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...            47   \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...            29   \n",
       "3  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...            63   \n",
       "4  [{\"Label\": \"National Basketball Association\", ...            59   \n",
       "\n",
       "   abstract_length  title_reading_ease news_id  total_clicks  \\\n",
       "0               73               77.23     NaN           0.0   \n",
       "1               64                6.17     NaN           0.0   \n",
       "2              116               90.77     NaN           0.0   \n",
       "3              196              101.60     NaN           0.0   \n",
       "4               99               82.31     NaN           0.0   \n",
       "\n",
       "   total_impressions  ctr  \n",
       "0                0.0  0.0  \n",
       "1                0.0  0.0  \n",
       "2                0.0  0.0  \n",
       "3                0.0  0.0  \n",
       "4                0.0  0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "title    0\n",
      "ctr      0\n",
      "dtype: int64\n",
      "Data loaded successfully\n",
      "   newsID   category               subcategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N93187       news                 newsworld   \n",
      "4  N75236     health                    voices   \n",
      "\n",
      "                                               title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "4  I Was An NBA Wife. Here's How It Affected My M...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "4  I felt like I was a fraud, and being an NBA wi...   \n",
      "\n",
      "                                             url  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "4  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
      "\n",
      "                                      title_entities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3                                                 []   \n",
      "4                                                 []   \n",
      "\n",
      "                                   abstract_entities  title_length  \\\n",
      "0                                                 []            70   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...            47   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...            29   \n",
      "3  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...            63   \n",
      "4  [{\"Label\": \"National Basketball Association\", ...            59   \n",
      "\n",
      "   abstract_length  title_reading_ease news_id  total_clicks  \\\n",
      "0               73               77.23     NaN           0.0   \n",
      "1               64                6.17     NaN           0.0   \n",
      "2              116               90.77     NaN           0.0   \n",
      "3              196              101.60     NaN           0.0   \n",
      "4               99               82.31     NaN           0.0   \n",
      "\n",
      "   total_impressions  ctr  \n",
      "0                0.0  0.0  \n",
      "1                0.0  0.0  \n",
      "2                0.0  0.0  \n",
      "3                0.0  0.0  \n",
      "4                0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "# Define data directory\n",
    "processed_data_dir = 'agentic_news_editor/processed_data'\n",
    "\n",
    "def load_training_data(data_dir=processed_data_dir):\n",
    "    \"\"\"Load processed headlines with CTR data\"\"\"\n",
    "    try:\n",
    "        headlines_path = os.path.join(data_dir, 'news_with_engagement.csv')\n",
    "        if not os.path.exists(headlines_path):\n",
    "            print(f\"Training data not found at {headlines_path}\")\n",
    "            return None\n",
    "                \n",
    "        headline_data = pd.read_csv(headlines_path)\n",
    "        print(f\"Loaded {len(headline_data)} headlines with CTR data\")\n",
    "        \n",
    "        # Preview the data\n",
    "        print(\"\\nData preview:\")\n",
    "        display(headline_data.head())\n",
    "        \n",
    "        # Check for missing values\n",
    "        print(\"\\nMissing values:\")\n",
    "        print(headline_data[['title', 'ctr']].isna().sum())\n",
    "        \n",
    "        return headline_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading training data: {e}\")\n",
    "        return None\n",
    "# Explicitly call the function and store the result\n",
    "print(\"About to call load_training_data()\")\n",
    "headline_data = load_training_data()\n",
    "\n",
    "# Check if data was loaded\n",
    "if headline_data is not None:\n",
    "    print(\"Data loaded successfully\")\n",
    "    print(headline_data.head())  # Using print instead of display\n",
    "else:\n",
    "    print(\"Failed to load data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee4f26",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cf6a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data shape: (95492, 15)\n",
      "Extracting features from 95492 headlines\n",
      "Using first 100 headlines for testing\n",
      "Processing batch 1/5\n",
      "Processing batch 2/5\n",
      "Processing batch 3/5\n",
      "Processing batch 4/5\n",
      "Processing batch 5/5\n",
      "\n",
      "Feature statistics:\n",
      "          length  word_count  has_number   num_count  is_question   has_colon  \\\n",
      "count  100.00000  100.000000  100.000000  100.000000    100.00000  100.000000   \n",
      "mean    61.61000   10.470000    0.410000    0.540000      0.15000    0.130000   \n",
      "std     17.09681    3.056554    0.494311    0.757721      0.35887    0.337998   \n",
      "min     16.00000    3.000000    0.000000    0.000000      0.00000    0.000000   \n",
      "25%     52.00000    9.000000    0.000000    0.000000      0.00000    0.000000   \n",
      "50%     60.00000   10.000000    0.000000    0.000000      0.00000    0.000000   \n",
      "75%     71.00000   12.000000    1.000000    1.000000      0.00000    0.000000   \n",
      "max    112.00000   20.000000    1.000000    3.000000      1.00000    1.000000   \n",
      "\n",
      "        has_quote  has_how_to       emb_0       emb_1       emb_2       emb_3  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean     0.280000    0.060000   -0.198226   -0.138257   -0.039989   -0.092448   \n",
      "std      0.451261    0.238683    0.166605    0.132421    0.200351    0.132172   \n",
      "min      0.000000    0.000000   -0.770741   -0.455757   -0.494178   -0.663435   \n",
      "25%      0.000000    0.000000   -0.304273   -0.222210   -0.188201   -0.173928   \n",
      "50%      0.000000    0.000000   -0.204511   -0.128588   -0.024610   -0.086236   \n",
      "75%      1.000000    0.000000   -0.096337   -0.031328    0.085684   -0.009397   \n",
      "max      1.000000    1.000000    0.176354    0.100750    0.413613    0.178887   \n",
      "\n",
      "            emb_4       emb_5       emb_6       emb_7       emb_8       emb_9  \n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000  \n",
      "mean     0.014116   -0.139676    0.257184    0.375125   -0.119800   -0.203349  \n",
      "std      0.143991    0.149887    0.124313    0.169075    0.139794    0.168203  \n",
      "min     -0.469449   -0.719481    0.028895    0.028890   -0.510747   -0.661056  \n",
      "25%     -0.065648   -0.231337    0.164904    0.266959   -0.202639   -0.294425  \n",
      "50%      0.024203   -0.123821    0.245022    0.365613   -0.125551   -0.186187  \n",
      "75%      0.102729   -0.042381    0.332939    0.485273   -0.051027   -0.071479  \n",
      "max      0.399512    0.178553    0.655155    0.817035    0.372125    0.183362  \n"
     ]
    }
   ],
   "source": [
    "def extract_features(headlines, tokenizer=tokenizer, bert_model=bert_model, device=device):\n",
    "    \"\"\"Extract features from headlines for model training\"\"\"\n",
    "    print(f\"Extracting features from {len(headlines)} headlines\")\n",
    "    features_list = []\n",
    "    \n",
    "    # Process in smaller batches to avoid memory issues\n",
    "    batch_size = 20  # Smaller for notebook testing\n",
    "    \n",
    "    # Sample a few headlines for testing in notebook\n",
    "    if len(headlines) > 100:\n",
    "        test_headlines = headlines[:100]\n",
    "        print(f\"Using first 100 headlines for testing\")\n",
    "    else:\n",
    "        test_headlines = headlines\n",
    "    \n",
    "    for i in range(0, len(test_headlines), batch_size):\n",
    "        batch = test_headlines[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(len(test_headlines)-1)//batch_size + 1}\")\n",
    "        \n",
    "        for headline in batch:\n",
    "            features = {}\n",
    "            \n",
    "            # Basic features based on EDA findings\n",
    "            features['length'] = len(headline)\n",
    "            features['word_count'] = len(headline.split())\n",
    "            features['has_number'] = int(bool(re.search(r'\\d', headline)))\n",
    "            features['num_count'] = len(re.findall(r'\\d+', headline))\n",
    "            features['is_question'] = int(headline.endswith('?') or \n",
    "                                       headline.lower().startswith(('how', 'what', 'why', 'where', 'when', 'is ')))\n",
    "            features['has_colon'] = int(':' in headline)\n",
    "            features['has_quote'] = int('\"' in headline or \"'\" in headline)\n",
    "            features['has_how_to'] = int('how to' in headline.lower())\n",
    "            \n",
    "            # Get embedding for semantic features\n",
    "            try:\n",
    "                inputs = tokenizer(headline, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = bert_model(**inputs)\n",
    "                \n",
    "                # Use the [CLS] token embedding\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()[0]\n",
    "                \n",
    "                # Add first 10 embedding dimensions as features\n",
    "                for j in range(10):\n",
    "                    features[f'emb_{j}'] = embedding[j]\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting embedding for '{headline}': {e}\")\n",
    "                # Add zero embeddings if failed\n",
    "                for j in range(10):\n",
    "                    features[f'emb_{j}'] = 0.0\n",
    "            \n",
    "            features_list.append(features)\n",
    "    \n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    \n",
    "    # Display feature statistics\n",
    "    print(\"\\nFeature statistics:\")\n",
    "    print(features_df.describe())\n",
    "    \n",
    "    return features_df\n",
    "\n",
    "# Clean data and extract features\n",
    "if headline_data is not None:\n",
    "    # Handle NaN values\n",
    "    clean_headline_data = headline_data.dropna(subset=['title', 'ctr'])\n",
    "    print(f\"Clean data shape: {clean_headline_data.shape}\")\n",
    "    \n",
    "    # Extract features for a sample\n",
    "    features_df = extract_features(clean_headline_data['title'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7733c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9973765",
   "metadata": {},
   "source": [
    "def train_model(features_df, ctr_values, output_file='headline_ctr_model.pkl'):\n",
    "    \"\"\"Train a model to predict headline CTR\"\"\"\n",
    "    print(\"Training headline CTR prediction model\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features_df, ctr_values, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # Define and train model\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model evaluation - MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': features_df.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 important features:\")\n",
    "    for i, row in feature_importances.head(10).iterrows():\n",
    "        print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importances.head(10))\n",
    "    plt.title('Top 10 Feature Importances for CTR Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model - comment this out during testing if desired\n",
    "    # with open(output_file, 'wb') as f:\n",
    "    #     pickle.dump(model, f)\n",
    "    # print(f\"Model saved to {output_file}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'feature_importances': feature_importances\n",
    "    }\n",
    "\n",
    "# Train model if features are available\n",
    "if 'features_df' in locals() and len(features_df) > 0:\n",
    "    result = train_model(features_df, clean_headline_data['ctr'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fedd89",
   "metadata": {},
   "source": [
    "## Model Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b4609",
   "metadata": {},
   "source": [
    "def create_model_report(result, headline_data, save_to_file=False):\n",
    "    \"\"\"Create a markdown report about the model performance\"\"\"\n",
    "    if result is None:\n",
    "        print(\"No model result to report\")\n",
    "        return\n",
    "    \n",
    "    report = f\"\"\"# Headline CTR Prediction Model Report\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "## Model Performance\n",
    "- Mean Squared Error: {result['mse']:.4f}\n",
    "- R-squared: {result['r2']:.4f}\n",
    "\n",
    "## Dataset Summary\n",
    "- Total headlines analyzed: {len(headline_data)}\n",
    "- CTR range: {headline_data['ctr'].min():.2f} to {headline_data['ctr'].max():.2f}\n",
    "- Mean CTR: {headline_data['ctr'].mean():.2f}\n",
    "\n",
    "## Key Feature Importances\n",
    "\"\"\"\n",
    "    \n",
    "    for i, row in result['feature_importances'].head(10).iterrows():\n",
    "        report += f\"- {row['feature']}: {row['importance']:.4f}\\n\"\n",
    "    \n",
    "    report += \"\"\"\n",
    "## Usage Guidelines\n",
    "This model can be used to predict the expected CTR of news headlines.\n",
    "It's integrated with the HeadlineMetrics class for headline evaluation\n",
    "and the HeadlineLearningLoop for continuous improvement.\n",
    "\n",
    "## Features Based on EDA\n",
    "The model uses features derived from EDA findings:\n",
    "- Questions in headlines significantly reduce CTR\n",
    "- Numbers in headlines can reduce CTR if used inappropriately\n",
    "- Headline length and structure matter for engagement\n",
    "- Category-specific patterns influence performance\n",
    "\"\"\"\n",
    "    \n",
    "    # Print report for notebook review\n",
    "    print(report)\n",
    "    \n",
    "    # Save to file if requested\n",
    "    if save_to_file:\n",
    "        with open('headline_model_report.md', 'w') as f:\n",
    "            f.write(report)\n",
    "        print(\"Model report saved to headline_model_report.md\")\n",
    "\n",
    "# Create report if results are available\n",
    "if 'result' in locals() and result is not None:\n",
    "    create_model_report(result, clean_headline_data, save_to_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3435206",
   "metadata": {},
   "source": [
    "## Full Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bcb05",
   "metadata": {},
   "source": [
    "def run_training_pipeline(save_model=False):\n",
    "    \"\"\"Run the complete model training pipeline\"\"\"\n",
    "    # Load data\n",
    "    headline_data = load_training_data()\n",
    "    if headline_data is None:\n",
    "        print(\"Could not load training data. Aborting.\")\n",
    "        return None\n",
    "    \n",
    "    # Handle NaN values\n",
    "    clean_data = headline_data.dropna(subset=['title', 'ctr'])\n",
    "    \n",
    "    # Extract features\n",
    "    features_df = extract_features(clean_data['title'].values)\n",
    "    \n",
    "    # Train model\n",
    "    result = train_model(features_df, clean_data['ctr'].values)\n",
    "    \n",
    "    # Create a report\n",
    "    create_model_report(result, headline_data, save_to_file=save_model)\n",
    "    \n",
    "    if save_model:\n",
    "        # Save model\n",
    "        with open('headline_ctr_model.pkl', 'wb') as f:\n",
    "            pickle.dump(result['model'], f)\n",
    "        print(\"Model saved to headline_ctr_model.pkl\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Uncommment to run full pipeline\n",
    "# final_result = run_training_pipeline(save_model=True)\n",
    "# if final_result is not None:\n",
    "#     print(f\"Model training complete. R-squared: {final_result['r2']:.4f}\")\n",
    "# else:\n",
    "#     print(\"Model training failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
